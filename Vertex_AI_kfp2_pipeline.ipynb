{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSKtE6ymJUXhinz3SgJOck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/03sarath/vertex-ai-mlops-kfp2/blob/main/Vertex_AI_kfp2_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copyright & License (click to expand)\n",
        "\n"
      ],
      "metadata": {
        "id": "9-TI4pWqwtBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copyright & License (click to expand)\n",
        "# Copyright 2023 Psitron Technologies Pvt Ltd\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "cellView": "form",
        "id": "mPWGmYoOwyg6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KqGdEbEnzNkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial uses the Vertex AI Pipelines with KFP 2.x.\n"
      ],
      "metadata": {
        "id": "1TRiBX7Vydfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective: **üç∑** **Predicting wine quality**\n",
        "\n",
        "In this tutorial, you learn to use `Vertex AI Pipelines` and KFP 2.x version of `Google Cloud Pipeline Components` to train and deploy an RandomForestClassifier model.\n",
        "\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Pipelines`\n",
        "- `Google Cloud Pipeline Components`\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Create a KFP pipeline:\n",
        "    - Data preprocessing.\n",
        "    - Train an RandomForestClassifier `Model`.\n",
        "    - Evaluation an `Model`.\n",
        "    - Create an `Endpoint` resource.\n",
        "    - Deploys the `Model` resource to the `Endpoint` resource.\n",
        "- Compile the KFP pipeline.\n",
        "- Execute the KFP pipeline using `Vertex AI Pipelines`\n",
        "\n",
        "The components are [documented here](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-1.0.0/google_cloud_pipeline_components.aiplatform.html)."
      ],
      "metadata": {
        "id": "fDkTQK2byqng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Vertex AI SDK for Python and other required packages"
      ],
      "metadata": {
        "id": "7--JpMcW0EdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install --no-cache-dir --upgrade \"kfp>2\" \\\n",
        "                                        google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "Nq_hAZ1Kf7vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the KFP SDK version."
      ],
      "metadata": {
        "id": "f7zFADcz0OjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
        "! pip3 freeze | grep aiplatform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHvQT1QyjyAI",
        "outputId": "995c6c88-858c-47f6-ea86-62d6d29f541f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KFP SDK version: 2.9.0\n",
            "google-cloud-aiplatform==1.66.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ],
      "metadata": {
        "id": "mmbQNoPK0UOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "oPrtAmw-j0ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab."
      ],
      "metadata": {
        "id": "gY_3hvoW0alG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "1hdXCFysj24r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "R7OB6vuq0mvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PROJECT_ID = \"vertexai-435412\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"\n",
        "BQ_LOCATION = LOCATION.split(\"-\")[0].upper()"
      ],
      "metadata": {
        "id": "fz8d9x2cj49B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ],
      "metadata": {
        "id": "gD4lXmAi0qc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "it6Gcfuej980"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bucket\n",
        "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root_wine/\"\n",
        "PIPELINE_ROOT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nRKJLwnvlQ2x",
        "outputId": "5c28315f-5f26-40ce-9b03-e6835489bb98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gs://your-bucket-name-vertexai-435412-unique/pipeline_root_wine/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ],
      "metadata": {
        "id": "AMa6M5VF024e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb3f1KatkAYh",
        "outputId": "94b6c40c-d7ed-45ee-8676-a8a1ef6eba1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://your-bucket-name-vertexai-435412-unique/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'your-bucket-name-vertexai-435412-unique' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Service Account\n",
        "\n",
        "You use a service account to create Vertex AI Pipeline jobs."
      ],
      "metadata": {
        "id": "kDSxFztA08eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "hSuFfAkSkCLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if (\n",
        "    SERVICE_ACCOUNT == \"\"\n",
        "    or SERVICE_ACCOUNT is None\n",
        "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
        "):\n",
        "    # Get your service account from gcloud\n",
        "    if not IS_COLAB:\n",
        "        shell_output = !gcloud auth list 2>/dev/null\n",
        "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
        "\n",
        "    else:  # IS_COLAB:\n",
        "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
        "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "    print(\"Service Account:\", SERVICE_ACCOUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7h-ZvVFkKJ5",
        "outputId": "0c70f8b0-cda9-44f0-dd07-7729b7ed5deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Service Account: 77267352267-compute@developer.gserviceaccount.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set service account access for Vertex AI Pipelines\n",
        "\n",
        "Run the following commands to grant your service account access to read and write pipeline artifacts in the bucket that you created in the previous step. You only need to run this step once per service account."
      ],
      "metadata": {
        "id": "cUjwDiee4elj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
        "\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
      ],
      "metadata": {
        "id": "U-ik0LAwkMDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries and define constants"
      ],
      "metadata": {
        "id": "16-VDfT94jzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "import kfp\n",
        "from kfp import compiler, dsl\n",
        "from kfp.dsl import Artifact, Dataset, Input, Metrics, Model, Output, component, ClassificationMetrics\n",
        "from typing import NamedTuple\n",
        "from google.cloud.aiplatform import pipeline_jobs\n"
      ],
      "metadata": {
        "id": "Ec1rCWCukUih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ],
      "metadata": {
        "id": "4uECwurO4muD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
      ],
      "metadata": {
        "id": "ybmnn0rXkWk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Data preparation component\n"
      ],
      "metadata": {
        "id": "4hnvbin-4qw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    packages_to_install=[\"pandas==1.3.5\", \"pyarrow\", \"scikit-learn==1.0.2\"],\n",
        ")\n",
        "\n",
        "def get_wine_data(\n",
        "    url: str,\n",
        "    dataset_train: Output[Dataset],\n",
        "    dataset_test: Output[Dataset]\n",
        "):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "    df_wine = pd.read_csv(url, delimiter=\";\")\n",
        "    df_wine['best_quality'] = [ 1 if x>=7 else 0 for x in df_wine.quality]\n",
        "    df_wine['target'] = df_wine.best_quality\n",
        "    df_wine = df_wine.drop(['quality', 'total sulfur dioxide', 'best_quality'], axis=1)\n",
        "\n",
        "\n",
        "    train, test = tts(df_wine, test_size=0.3)\n",
        "    train.to_csv(dataset_train.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
        "    test.to_csv(dataset_test.path + \".csv\" , index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2v6ISuvkbwQ",
        "outputId": "4b143d9e-36ee-4a9a-dca6-d915bc4d653f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/kfp/dsl/component_decorator.py:121: FutureWarning: The default base_image used by the @dsl.component decorator will switch from 'python:3.8' to 'python:3.9' on Oct 1, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.9.\n",
            "  return component_factory.create_component_from_func(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define RandomForestClassifier Model training component\n"
      ],
      "metadata": {
        "id": "JXUy7ydu5EQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.5\",\n",
        "        \"scikit-learn==1.0.2\"\n",
        "    ]\n",
        ")\n",
        "def train_winequality(\n",
        "    dataset:  Input[Dataset],\n",
        "    model: Output[Model],\n",
        "):\n",
        "\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    import pandas as pd\n",
        "    import pickle\n",
        "\n",
        "    data = pd.read_csv(dataset.path+\".csv\")\n",
        "    model_rf = RandomForestClassifier(n_estimators=10)\n",
        "    model_rf.fit(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "    model.metadata[\"framework\"] = \"RF\"\n",
        "    file_name = model.path + f\".pkl\"\n",
        "    with open(file_name, 'wb') as file:\n",
        "        pickle.dump(model_rf, file)"
      ],
      "metadata": {
        "id": "jJ1YlQjlkf3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Model evaluation component\n"
      ],
      "metadata": {
        "id": "zj-z1lTz5NoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas\",\n",
        "        \"scikit-learn==1.0.2\"\n",
        "    ]\n",
        ")\n",
        "def winequality_evaluation(\n",
        "    test_set:  Input[Dataset],\n",
        "    rf_winequality_model: Input[Model],\n",
        "    thresholds_dict_str: str,\n",
        "    metrics: Output[ClassificationMetrics],\n",
        "    kpi: Output[Metrics]\n",
        ") -> NamedTuple(\"output\", [(\"deploy\", str)]):\n",
        "\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    import pandas as pd\n",
        "    import logging\n",
        "    import pickle\n",
        "    from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score\n",
        "    import json\n",
        "    import typing\n",
        "\n",
        "\n",
        "    def threshold_check(val1, val2):\n",
        "        cond = \"false\"\n",
        "        if val1 >= val2 :\n",
        "            cond = \"true\"\n",
        "        return cond\n",
        "\n",
        "    data = pd.read_csv(test_set.path+\".csv\")\n",
        "    model = RandomForestClassifier()\n",
        "    file_name = rf_winequality_model.path + \".pkl\"\n",
        "    with open(file_name, 'rb') as file:\n",
        "        model = pickle.load(file)\n",
        "\n",
        "    y_test = data.drop(columns=[\"target\"])\n",
        "    y_target=data.target\n",
        "    y_pred = model.predict(y_test)\n",
        "\n",
        "\n",
        "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(\n",
        "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
        "    )\n",
        "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
        "\n",
        "    metrics.log_confusion_matrix(\n",
        "       [\"False\", \"True\"],\n",
        "       confusion_matrix(\n",
        "           data.target, y_pred\n",
        "       ).tolist(),\n",
        "    )\n",
        "\n",
        "    accuracy = accuracy_score(data.target, y_pred.round())\n",
        "    thresholds_dict = json.loads(thresholds_dict_str)\n",
        "    rf_winequality_model.metadata[\"accuracy\"] = float(accuracy)\n",
        "    kpi.log_metric(\"accuracy\", float(accuracy))\n",
        "    deploy = threshold_check(float(accuracy), int(thresholds_dict['roc']))\n",
        "    return (deploy,)\n"
      ],
      "metadata": {
        "id": "a36jSFlUkg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define deploying the model component\n",
        "\n",
        "Finally, you define a component to deploy the model."
      ],
      "metadata": {
        "id": "0wE0blhv5UT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    packages_to_install=[\"google-cloud-aiplatform\", \"scikit-learn==1.0.2\",  \"kfp\"],\n",
        "    output_component_file=\"model_winequality_coponent.yml\"\n",
        ")\n",
        "def deploy_winequality(\n",
        "    model: Input[Model],\n",
        "    project: str,\n",
        "    region: str,\n",
        "    serving_container_image_uri : str,\n",
        "    vertex_endpoint: Output[Artifact],\n",
        "    vertex_model: Output[Model]\n",
        "):\n",
        "    from google.cloud import aiplatform\n",
        "    aiplatform.init(project=project, location=region)\n",
        "\n",
        "    DISPLAY_NAME  = \"winequality\"\n",
        "    MODEL_NAME = \"winequality-rf\"\n",
        "    ENDPOINT_NAME = \"winequality_endpoint\"\n",
        "\n",
        "    def create_endpoint():\n",
        "        endpoints = aiplatform.Endpoint.list(\n",
        "        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
        "        order_by='create_time desc',\n",
        "        project=project,\n",
        "        location=region,\n",
        "        )\n",
        "        if len(endpoints) > 0:\n",
        "            endpoint = endpoints[0]  # most recently created\n",
        "        else:\n",
        "            endpoint = aiplatform.Endpoint.create(\n",
        "            display_name=ENDPOINT_NAME, project=project, location=region\n",
        "        )\n",
        "    endpoint = create_endpoint()\n",
        "\n",
        "\n",
        "    #Import a model programmatically\n",
        "    model_upload = aiplatform.Model.upload(\n",
        "        display_name = DISPLAY_NAME,\n",
        "        artifact_uri = model.uri.replace(\"model\", \"\"),\n",
        "        serving_container_image_uri =  serving_container_image_uri,\n",
        "        serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n",
        "        serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\",\n",
        "        serving_container_environment_variables={\n",
        "        \"MODEL_NAME\": MODEL_NAME,\n",
        "    },\n",
        "    )\n",
        "    model_deploy = model_upload.deploy(\n",
        "        machine_type=\"n1-standard-4\",\n",
        "        endpoint=endpoint,\n",
        "        traffic_split={\"0\": 100},\n",
        "        deployed_model_display_name=DISPLAY_NAME,\n",
        "    )\n",
        "\n",
        "    # Save data to the output params\n",
        "    vertex_model.uri = model_deploy.resource_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_xp-Wa6k5CA",
        "outputId": "accb3b5c-7d39-4d9e-cdea-355e396e2ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-7d84ca2e2b00>:1: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @component(\n",
            "<ipython-input-14-7d84ca2e2b00>:5: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def deploy_winequality(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP =datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "DISPLAY_NAME = 'pipeline-winequality-job{}'.format(TIMESTAMP)"
      ],
      "metadata": {
        "id": "OjJ1j_zok6aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the RandomForestClassifier training pipeline\n",
        "\n",
        "Now you define the pipeline, with the following steps:\n",
        "\n",
        "- Data preparation.\n",
        "- Train the model.\n",
        "- Evaluate the model.\n",
        "- Deploy the model."
      ],
      "metadata": {
        "id": "E6FR1JZr5gv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"pipeline-winequality\",\n",
        "\n",
        ")\n",
        "def pipeline(\n",
        "    url: str = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
        "    project: str = PROJECT_ID,\n",
        "    region: str = LOCATION,\n",
        "    display_name: str = DISPLAY_NAME,\n",
        "    api_endpoint: str = LOCATION+\"-aiplatform.googleapis.com\",\n",
        "    thresholds_dict_str: str = '{\"roc\":0.8}',\n",
        "    serving_container_image_uri: str = \"europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
        "    ):\n",
        "\n",
        "    data_op = get_wine_data(url=url)\n",
        "    train_model_op = train_winequality(dataset=data_op.outputs[\"dataset_train\"])\n",
        "    model_evaluation_op = winequality_evaluation(\n",
        "        test_set=data_op.outputs[\"dataset_test\"],\n",
        "        rf_winequality_model=train_model_op.outputs[\"model\"],\n",
        "        thresholds_dict_str = thresholds_dict_str, # I deploy the model anly if the model performance is above the threshold\n",
        "    )\n",
        "\n",
        "    with dsl.Condition(\n",
        "        model_evaluation_op.outputs[\"deploy\"]==\"true\",\n",
        "        name=\"deploy-winequality\",\n",
        "    ):\n",
        "\n",
        "        deploy_model_op = deploy_winequality(\n",
        "        model=train_model_op.outputs['model'],\n",
        "        project=project,\n",
        "        region=region,\n",
        "        serving_container_image_uri = serving_container_image_uri,\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L9Q_IZIk8_K",
        "outputId": "92c978ae-00c9-4525-ff68-a9b2c56e09dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-b6168f0b3c6d>:26: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
            "  with dsl.Condition(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the pipeline\n",
        "\n",
        "Next, you compile the pipeline."
      ],
      "metadata": {
        "id": "D1hf0Gig6s35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(pipeline_func=pipeline,\n",
        "        package_path='ml_winequality.json')"
      ],
      "metadata": {
        "id": "gg-qAXBclssl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the pipeline using Vertex AI Pipelines\n",
        "\n",
        "Now, run the compiled pipeline."
      ],
      "metadata": {
        "id": "baLHR8486x94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_pipeline = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"winequality-pipeline\",\n",
        "    template_path=\"ml_winequality.json\",\n",
        "    enable_caching=False,\n",
        "    location=LOCATION,\n",
        ")"
      ],
      "metadata": {
        "id": "rmHFzOEol0iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_pipeline.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nqYV60DmApf",
        "outputId": "c047f9ed-edce-4c66-ca1f-3977e82edc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/77267352267/locations/us-central1/pipelineJobs/pipeline-winequality-20240912143357\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/77267352267/locations/us-central1/pipelineJobs/pipeline-winequality-20240912143357')\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pipeline-winequality-20240912143357?project=77267352267\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/77267352267/locations/us-central1/pipelineJobs/pipeline-winequality-20240912143357 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/77267352267/locations/us-central1/pipelineJobs/pipeline-winequality-20240912143357 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è∞ **Schedule** your pipelines to run recurrently"
      ],
      "metadata": {
        "id": "oxnLI5zL64u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Schedule your pipelines to run recurrently\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "pipeline_job = aiplatform.PipelineJob(\n",
        "  template_path=\"ml_winequality.json\",\n",
        "  pipeline_root=PIPELINE_ROOT,\n",
        "  display_name=\"ml_winequality\",\n",
        ")\n",
        "\n",
        "pipeline_job_schedule = aiplatform.PipelineJobSchedule(\n",
        "  pipeline_job=pipeline_job,\n",
        "  display_name=\"ml_winequality\"\n",
        ")\n",
        "\n",
        "pipeline_job_schedule.create(\n",
        "  cron=\"0 0 * * *\",\n",
        "  max_concurrent_run_count=1,\n",
        "  max_run_count=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPOhGaMLAm3l",
        "outputId": "3914fdbb-df16-454a-c4ab-551b09fbaab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_job_schedules:Creating PipelineJobSchedule\n",
            "INFO:google.cloud.aiplatform.pipeline_job_schedules:PipelineJobSchedule created. Resource name: projects/1027839402068/locations/us-central1/schedules/7235938798951989248\n",
            "INFO:google.cloud.aiplatform.pipeline_job_schedules:To use this PipelineJobSchedule in another session:\n",
            "INFO:google.cloud.aiplatform.pipeline_job_schedules:schedule = aiplatform.PipelineJobSchedule.get('projects/1027839402068/locations/us-central1/schedules/7235938798951989248')\n",
            "INFO:google.cloud.aiplatform.pipeline_job_schedules:View Schedule:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/schedules/7235938798951989248?project=1027839402068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚è∞List your all scheduled pipelines\n"
      ],
      "metadata": {
        "id": "Vnrg_M0A7GKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List your all scheduled pipelines\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.PipelineJobSchedule.list(\n",
        "  filter='display_name=\"ml_winequality\"',\n",
        "  order_by='create_time desc'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwmZv-gmBEnG",
        "outputId": "5f23efea-b5ad-4e49-f904-fdd042db3485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<google.cloud.aiplatform.pipeline_job_schedules.PipelineJobSchedule object at 0x7fa2bcc226b0> \n",
              " resource name: projects/1027839402068/locations/us-central1/schedules/7235938798951989248]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Invoke **ML model deployed in vertex ai endpoint**"
      ],
      "metadata": {
        "id": "C1HHtQd27W8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "ENDPOINT_NAME = \"winequality_endpoint\"\n",
        "\n",
        "#Bad Qty Wine Data üëé\n",
        "instance = [[7.2, 0.23, 0.32, 8.5, 0.058, 47, 132, 0.993, 3.12, 0.46]]\n",
        "\n",
        "#Good Qty Wine Data üëç\n",
        "#instance = [[6.7,0.23,0.31,2.1,0.046,30,0.9926,3.33,0.64,10.7]]\n",
        "\n",
        "\n",
        "def endpoint_predict(project: str, location: str, instances: list, endpoint: str):\n",
        "    aiplatform.init(project=project, location=location)\n",
        "    endpoint = aiplatform.Endpoint(endpoint)\n",
        "    prediction = endpoint.predict(instances=instances)\n",
        "    return prediction\n",
        "\n",
        "#prediction = endpoint_predict('<project_id>', 'us-central1', instance, '<endpoint_id>')\n",
        "prediction = endpoint_predict('vertex-435406', 'us-central1', instance, '8295139031918837760')\n",
        "print(\"Prediction from Deployed model_id:\", prediction[1])\n",
        "print(\"Prediction from Deployed model version_id:\", prediction[3])\n",
        "print(\"Predicted wine quality üç∑üëçüëé:\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6aq7mzCBHTk",
        "outputId": "82a4c4de-9280-4524-bee7-de5129a5b835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction from Deployed model_id: 2807054285223755776\n",
            "Prediction from Deployed model version_id: 1\n",
            "Predicted wine quality üç∑üëçüëé: [0.0]\n"
          ]
        }
      ]
    }
  ]
}